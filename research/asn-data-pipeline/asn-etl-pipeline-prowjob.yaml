# Run as ProwJob
# Usually, this will be declared in a Prow /config/ style local file.
# The ProwJob resource is used here to get it working.


apiVersion: prow.k8s.io/v1
kind: ProwJob
metadata:
  annotations:
    prow.k8s.io/context: ""
    prow.k8s.io/job: asn-data-pipeline
  labels:
    created-by-prow: "true"
    prow.k8s.io/context: ""
    prow.k8s.io/job: asn-data-pipeline
    prow.k8s.io/type: periodic
  name: asn-data-pipeline
  namespace: prow
spec:
  agent: kubernetes
  cluster: default
  decoration_config:
    gcs_configuration:
      bucket: s3://prow-logs
      path_strategy: explicit
    s3_credentials_secret: prow-s3-credentials
    utility_images:
      clonerefs: gcr.io/k8s-prow/clonerefs:v20210504-af1ac03335
      entrypoint: gcr.io/k8s-prow/entrypoint:v20210504-af1ac03335
      initupload: gcr.io/k8s-prow/initupload:v20210504-af1ac03335
      sidecar: gcr.io/k8s-prow/sidecar:v20210504-af1ac03335
  job: asn-data-pipeline
  namespace: prow-workloads
  pod_spec:
    containers:
      - name: asn-etl-pipeline
        image: asn-etl-pipeline
        imagePullPolicy: Never
        volumeMounts:
          - name: gcp-app-creds
            mountPath: /etc/asn-etl-pipeline
        env:
          - name: POSTGRES_PASSWORD
            value: postgres
          - name: GCP_PROJECT
            value: k8s-infra-ii-sandbox
          - name: GCP_SERVICEACCOUNT
            value: asn-etl@k8s-infra-ii-sandbox.iam.gserviceaccount.com
          - name: GCP_BIGQUERY_DATASET
            value: etl_script_generated_set
          - name: GCP_BIGQUERY_DATASET_LOGS
            value: etl_script_generated_set_prod
          - name: GOOGLE_APPLICATION_CREDENTIALS
            value: /etc/asn-etl-pipeline/asn-etl-pipeline-gcp-sa.json
          - name: ASN_DATA_PIPELINE_RETAIN
            value: "false"
    volumes:
      - name: gcp-app-creds
        secret:
          secretName: gcp-app-creds
  report: true
  type: periodic
