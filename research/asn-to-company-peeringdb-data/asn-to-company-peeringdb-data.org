#+TITLE: K8s Reg Asn Magic
#+PROPERTY: header-args:tmate+ :socket /tmp/ii.default.target.iisocket
#+PROPERTY: header-args:sql-mode+ :eval never-export :exports both :session none

Login to gcloud
#+BEGIN_SRC tmate :window prepare
gcloud auth login
#+END_SRC

Set the project
#+BEGIN_SRC tmate :window prepare
gcloud config set project k8s-infra-ii-sandbox
#+END_SRC

* Parse from API
Save the data to a bucket
#+BEGIN_SRC tmate :window prepare
bq extract --destination_format NEWLINE_DELIMITED_JSON k8s_artifacts_gcslogs_appspot.riaan_ipv4_asn_ip_name_over_2500 gs://ii_bq_scratch_dump/ip-and-asn.json
#+END_SRC

Download the data from the bucket
#+BEGIN_SRC tmate :window prepare
gsutil cp gs://ii_bq_scratch_dump/ip-and-asn.json ip-and-asn.json
#+END_SRC

Store only the ASN
#+BEGIN_SRC tmate :window prepare
cat ip-and-asn.json | jq -r '.asn' | sort | uniq > asns.txt
#+END_SRC

Formatting the data
#+BEGIN_SRC shell :tangle ./asn-data-processor.sh :results silent
#!/bin/bash

SKIP_TO=$1
READ_FROM=asns.txt
WRITE_TO=asn-data.csv

TMPDIR=$(mktemp -d)
echo "Temp folder: $TMPDIR"

ALLOWED_RETRIES=5

count=0
while IFS= read -r asn; do
    count=$((count+=1))
    retries=0
    echo "ASN[$count]: $asn"
    if [ $asn -eq 0 ] || ( [ ! -z $SKIP_TO ] && [ $count -lt $SKIP_TO ] ); then
        echo "Skipping [$count] $asn"
        continue
    fi
    until curl "https://api.bgpview.io/asn/$asn" 2> /dev/null > $TMPDIR/$asn.json && cat $TMPDIR/$asn.json | jq .data.name 2>&1 > /dev/null; do
        retries=$((retries+=1))
        if [ $retries -eq $ALLOWED_RETRIES ]; then
            echo "Skipping [$count] $asn"
            retries=0
            continue 2
        fi
        echo "Failed [$retries/$ALLOWED_RETRIES]. Retrying '$asn' in 3 seconds"
        sleep 3s
    done
    cat $TMPDIR/$asn.json | jq -r '.data | (.email_contacts | join(";")) as $contacts | .description_short as $name | [.asn, $name, $contacts] | @csv' 2> /dev/null \
        | tee -a $WRITE_TO 2>&1 > /dev/null
    sleep 1s
done < $READ_FROM
#+END_SRC

Run the script
#+BEGIN_SRC tmate :window prepare
chmod +x ./asn-data-processor.sh
time ./asn-data-processor.sh
#+END_SRC

Upload to the bucket
#+BEGIN_SRC shell :results silent
gsutil cp ./asn-data.csv gs://ii_bq_scratch_dump/asn-data.csv
gsutil ls $_
#+END_SRC

Load into big query
#+BEGIN_SRC shell :results silent
bq load --autodetect --source_format=CSV k8s_artifacts_gcslogs_appspot.asn_company_lookup gs://ii_bq_scratch_dump/asn-data.csv
#+END_SRC

* Parse from Postgres

Bring up Postgres
#+BEGIN_SRC tmate :window postgres
docker run -it --rm -p 5432:5432 -e POSTGRES_PASSWORD=password -e POSTGRES_DB=peeringdb postgres:12.2-alpine
#+END_SRC

Clone https://git.2e8.dk/peeringdb-simplesync
#+BEGIN_SRC tmate :window prepare :dir (getenv "HOME")
git clone https://git.2e8.dk/peeringdb-simplesync
cd peeringdb-simplesync
#+END_SRC

Enter PeeringDB creds
#+BEGIN_SRC tmate :window prepare :dir (concat (getenv "HOME") "/peeringdb-simplesync")
read -p 'PEERINGDB_USER    : ' PEERINGDB_USER
read -p 'PEERINGDB_PASSWORD: ' PEERINGDB_PASSWORD
#+END_SRC

Write the config for sync.py
#+BEGIN_SRC python :tangle (concat (getenv "HOME") "/peeringdb-simplesync/config.py")
from requests.auth import HTTPBasicAuth
import os

host=os.environ['SHARINGIO_PAIR_LOAD_BALANCER_IP']
user=os.environ['PEERINGDB_USER']
password=os.environ['PEERINGDB_PASSWORD']

def get_config():
    return {
        'db_conn_str': 'dbname=peeringdb host=%s user=postgres password=password' % host,
        'db_schema': 'peeringdb',
        'auth': HTTPBasicAuth('%s' % user, '%s' % password),
    }
#+END_SRC

Dump all of the data
#+BEGIN_SRC tmate :window peeringdb-sync :dir (concat (getenv "HOME") "/peeringdb-simplesync")
./sync
#+END_SRC

Set env vars to not prompt for Postgres username and password
#+BEGIN_SRC tmate :window peeringdb-sync :dir (concat (getenv "HOME") "/peeringdb-simplesync")
export \
    PGUSER=postgres \
    PGPASSWORD=password
#+END_SRC

Dump the database
#+BEGIN_SRC tmate :window peeringdb-sync :dir (concat (getenv "HOME") "/peeringdb-simplesync")
pg_dump -U postgres -d peeringdb -h $SHARINGIO_PAIR_LOAD_BALANCER_IP > peeringdb-dump-$(date +%Y%m%d).sql
#+END_SRC

Upload the dump
#+BEGIN_SRC tmate :window peeringdb-sync
gsutil cp peeringdb-dump-$(date +%Y%m%d).sql gs://ii_bq_scratch_dump/peeringdb-dump-$(date +%Y%m%d).sql
#+END_SRC

** With pre-prepared dump

Download from the bucket
#+BEGIN_SRC tmate :window peeringdb-sync
gsutil cp gs://ii_bq_scratch_dump/peeringdb-dump-20210512.sql ./peeringdb-dump-20210512.sql
#+END_SRC

Load the data from the dump into a new/separate Postgres instance
#+BEGIN_SRC tmate :window peeringdb-sync
psql -U postgres -d peeringdb -h $SHARINGIO_PAIR_LOAD_BALANCER_IP < ./peeringdb-dump-20210512.sql
#+END_SRC

** Explore

Connect with psql
#+BEGIN_SRC tmate :window peeringdb-sync
psql -U postgres -d peeringdb -h $SHARINGIO_PAIR_LOAD_BALANCER_IP
#+END_SRC

See the tables
#+BEGIN_SRC sql-mode :eval never-export :exports both :session none :sql-user postgres :sql-database peeringdb :sql-server (getenv "SHARINGIO_PAIR_LOAD_BALANCER_IP") :sql-password password
SELECT schemaname, tablename FROM pg_catalog.pg_tables WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';
#+END_SRC

#+RESULTS:
#+begin_SRC example
 schemaname | tablename
------------+-----------
 peeringdb  | fac
 peeringdb  | ix
 peeringdb  | ixfac
 peeringdb  | ixlan
 peeringdb  | ixpfx
 peeringdb  | net
 peeringdb  | netfac
 peeringdb  | netixlan
 peeringdb  | org
 peeringdb  | poc
(10 rows)

#+end_SRC

Find data from peeringdb.org table
#+BEGIN_SRC sql-mode
select id, data::jsonb ->> 'name' as name, data::jsonb ->> 'asn' as asn, data::jsonb ->> 'website' as "website" from peeringdb.org where 'website' is not null limit 5;
#+END_SRC

#+RESULTS:
#+begin_SRC example
 id |         name         | asn | website
----+----------------------+-----+---------
 46 | XS4ALL Internet B.V. |     |
 17 | DALnet IRC Network   |     |
 90 | Plushosting B.V.     |     |
 91 | YellowBrix           |     |
 92 | NYCX                 |     |
(5 rows)

#+end_SRC

Find data from peeringdb.net table
#+BEGIN_SRC sql-mode
select id, data::jsonb ->> 'name' as name, data::jsonb ->> 'asn' as asn, data::jsonb ->> 'website' as "website" from peeringdb.net limit 5;
#+END_SRC

#+RESULTS:
#+begin_SRC example
 id |         name         |  asn  |            website
----+----------------------+-------+--------------------------------
 83 | Cable&Wireless UK    | 5388  | http://www.cw.com/uk
 24 | DSLExtreme           | 19817 | http://www.dslextreme.com
 28 | New Edge Networks    | 19029 | http://www.newedgenetworks.com
 97 | Netservices Plc      | 15444 | http://www.netservicesplc.com
 36 | GrafiX Internet B.V. | 16131 | http://www.grafix.nl/
(5 rows)

#+end_SRC

Getting fields with emails
#+BEGIN_SRC sql-mode
select id, data::jsonb ->> 'name' as name, data::jsonb ->> 'email' as email, net_id from peeringdb.poc where status = 'ok' limit 5;
#+END_SRC

#+RESULTS:
#+begin_SRC example
 id  |            name            |            email             | net_id
-----+----------------------------+------------------------------+--------
 100 | Telefonica DE Peering Team | peering.de@telefonica.com    |    115
  48 | NOC                        | noc@stealth.net              |     26
  53 | 24x7 NOC                   | NOC.AUS.NATL.BBN@charter.com |      9
  23 | GTT NOC (outside the USA)  | noc@gtt.net                  |     14
 191 | Support                    | support@is.co.za             |    179
(5 rows)

#+end_SRC

Connect ASNs with emails by joining names between tables
#+BEGIN_SRC sql-mode
select net.id,
       (net.data ->> 'name') as "name",
       (net.data ->> 'asn') as "asn",
       (net.data ->> 'website') as website,
       (poc.data ->> 'email') as email
       from peeringdb.net net
       left join peeringdb.poc on ((peeringdb.poc.data ->> 'name') = net.data ->> 'name')
       where (net.data ->>'website') is not null
       order by email asc
       limit 5;
#+END_SRC

#+RESULTS:
#+begin_SRC example
  id   |          name          |  asn   |           website            |             email
-------+------------------------+--------+------------------------------+-------------------------------
 19305 | Wnett Fibra            | 268729 | http://www.wnettfibra.com.br |
 13590 | BAYNET                 | 131916 | http://www.baynet.ne.jp/     | BAYNET-peer@tokyobaynet.co.jp
 23234 | Sebastian-Wilhelm Graf | 213261 | http://sebastian-graf.at     | abuse@AS213261.net
 20819 | Hanqi Yang             | 208266 | https://network.alanyhq.com/ | abuse@alanyhq-global.net
 21509 | Dorian Galiana         | 208196 | https://as208196.net         | abuse@as208196.net
(5 rows)

#+end_SRC

#+BEGIN_SRC sql-mode
\d peeringdb.net
#+END_SRC

** Building with Postgres
#+BEGIN_SRC sql-mode
create schema asntocompany;
#+END_SRC

#+RESULTS:
#+begin_SRC example
CREATE SCHEMA
#+end_SRC

#+BEGIN_SRC sql-mode
begin;
create table asnproc (
       asn bigint not null primary key
);
\copy asnproc from '/home/ii/peeringdb-simplesync/asns.txt';
select *
       from asnproc
       limit 10 ;
rollback;
#+END_SRC

#+BEGIN_SRC sql-mode
\d
#+END_SRC

#+RESULTS:
#+begin_SRC example
Did not find any relations.
#+end_SRC

** Building with Go

Scripting the data fetching in Go
#+BEGIN_SRC go :tangle ./asn-db-data-processor.go
package main

import (
	"fmt"
	"log"
	"os"
	"database/sql"
	_ "github.com/lib/pq"
)

func GetDBConnection() (*sql.DB, error) {
	db, err := sql.Open("postgres", fmt.Sprintf("postgres://postgres:password@%v/peeringdb", os.Getenv("SHARINGIO_PAIR_LOAD_BALANCER_IP")))
	db.Ping()
	return db, err
}

func main() {
	db, err := GetDBConnection()
	if err != nil {
		log.Fatalln(err)
	}
	db.Ping()
}
#+END_SRC

#+RESULTS:
#+begin_SRC example
#+end_SRC

* Clean up
Remove the table
#+BEGIN_SRC shell
bq rm k8s_artifacts_gcslogs_appspot.asn_company_lookup
#+END_SRC

Clean up
#+BEGIN_SRC shell :results silent
rm -f asn-data.csv
#+END_SRC
